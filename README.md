# LocalSearchBench

> A benchmark for local search and recommendation systems

## Quick Links

- ğŸŒ **Demo Website**: [localsearchbench.github.io](https://localsearchbench.github.io)
- ğŸš€ **RAG Server**: See [server/README.md](server/README.md) for backend deployment
- ğŸ“„ **Paper**: Coming soon

## ğŸš€ Quick Start

### Option 1: One-Command Start (Recommended)

Start RAG server and tunnel monitor with automatic URL updates:

```bash
./start_with_monitor.sh
```

This will:
- âœ… Start RAG server on port 8000
- âœ… Start Cloudflare tunnel with auto-monitoring
- âœ… Automatically update frontend config when tunnel URL changes
- âœ… Run everything in background (tmux sessions)

Check status:
```bash
./check_status.sh
```

Stop all services:
```bash
./stop_all.sh
```

### Option 2: Manual Start

If you want to run the backend RAG server manually:

```bash
cd server
./start_rag_server.sh --data-dir /path/to/your/data --host 0.0.0.0 --port 8000
```

See [server/README.md](server/README.md) for detailed instructions.

### Tunnel Auto-Update

The tunnel monitor automatically:
- Detects when Cloudflare tunnel goes down
- Restarts the tunnel with a new URL
- Updates `static/js/config.js` automatically
- Logs all changes to `tunnel_updates.log`

See [TUNNEL_AUTO_UPDATE.md](TUNNEL_AUTO_UPDATE.md) for details.

## ğŸ“ Project Structure

```
localsearchbench.github.io/
â”œâ”€â”€ index.html              # Main website
â”œâ”€â”€ static/                 # Frontend assets
â”‚   â”œâ”€â”€ css/
â”‚   â”œâ”€â”€ js/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ videos/
â””â”€â”€ server/                 # RAG backend
    â”œâ”€â”€ README.md           # Server documentation
    â”œâ”€â”€ rag_server.py       # Main server code
    â”œâ”€â”€ start_rag_server.sh # Startup script
    â”œâ”€â”€ requirements.txt    # Python dependencies
    â”œâ”€â”€ Dockerfile          # Docker image
    â””â”€â”€ docker-compose.yml  # Docker setup
```

## ğŸŒŸ Features

- **Multi-City Support**: Search across 9 major Chinese cities
- **GPU-Accelerated RAG**: VLLM-powered embedding and reranking
- **Interactive Demo**: Web-based interface for testing
- **Scalable Backend**: FastAPI + FAISS vector search
- **Docker Support**: Easy deployment with Docker Compose
- **MCP Integration**: Use as AI tool in Claude Desktop, Cursor, and more! ğŸ†•

## ğŸ› ï¸ Development

### Frontend (Website)
Edit `index.html` and files in `static/` for the demo website.

### Backend (RAG Server)
See [server/README.md](server/README.md) for:
- Installation and setup
- Configuration options
- API documentation
- Troubleshooting

### MCP Tools (AI Integration)
See [mcp_tools/QUICKSTART.md](mcp_tools/QUICKSTART.md) for:
- 5-minute quick start guide
- Claude Desktop configuration
- Usage examples
- Troubleshooting

Reference: Based on [RL-Factory](https://github.com/bytedance/RL-Factory) MCP implementation

## ğŸ“– Citation

```bibtex
@article{localsearchbench2025,
  title={LocalSearchBench: A Benchmark for Local Search and Recommendation},
  author={Your Name},
  year={2025}
}
```

## ğŸ“„ License

This project is licensed under the MIT License.

## Website License
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
